import os
import requests
import pathlib
from bs4 import BeautifulSoup
from flask import Flask, request, jsonify, send_from_directory
from google import genai
from flask_cors import CORS
import re
from datetime import datetime, timedelta 
import feedparser  # RSS yayÄ±nlarÄ±nÄ± iÅŸlemek iÃ§in
import json  # JSON dosyasÄ± oluÅŸturmak iÃ§in
from apscheduler.schedulers.background import BackgroundScheduler  # Arka plan zamanlayÄ±cÄ±sÄ± iÃ§in

# Ã‡evre deÄŸiÅŸkenlerini yÃ¼kleme
from dotenv import load_dotenv
load_dotenv()

# ----------------------------------------------------
# DEPREM VE Ä°Ã‡ERÄ°K FONKSÄ°YONLARI (AynÄ± KalÄ±yor)
# ----------------------------------------------------

def get_article_content(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")
    except Exception as e:
        return "Hata: Siteye eriÅŸilemedi", ""

    title = soup.title.string.strip() if soup.title else "BaÅŸlÄ±k bulunamadÄ±"

    texts = []
    for tag in soup.find_all(['p', 'div', 'span', 'article']):
        t = tag.get_text(separator=' ', strip=True)
        if t:
            texts.append(t)
    article_text = " ".join(texts)

    if len(article_text) < 50 and soup.body:
        article_text = soup.body.get_text(separator=' ', strip=True)

    return title, article_text


def extract_info_from_text(text):
    magnitude = None
    location = None

    mag_match = re.search(r'(\d[\.,]?\d?)\s*(?:bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde|ÅŸiddetinde|depremi|sarsÄ±ntÄ±)', text)
    if mag_match:
        magnitude = float(mag_match.group(1).replace(",", "."))

    location_match = re.search(
        r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)\s*(?:\'de|\'da|\'ta|\'te|yakÄ±nlarÄ±nda)?\s+(?:deprem|sarsÄ±ntÄ±)', text
    )
    if location_match:
        location = location_match.group(1)

    return magnitude, location


def get_all_afad_earthquakes():
    AFAD_URL = "https://deprem.afad.gov.tr/last-earthquakes.html"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(AFAD_URL, headers=headers, timeout=10)
        res.raise_for_status()
        res.encoding = "utf-8"
        soup = BeautifulSoup(res.text, "html.parser")
        table = soup.find("table")
    except:
        return []

    if not table:
        return []

    rows = table.find_all("tr")[1:]
    records = []

    for row in rows:
        cols = row.find_all("td")
        if len(cols) >= 7:
            try:
                buyukluk = float(cols[5].text.strip())
            except:
                buyukluk = 0.0

            sehir = cols[6].text.strip()

            records.append({
                "BÃ¼yÃ¼klÃ¼k": buyukluk,
                "Åehir": sehir
            })
    return records


# ----------------------------------------------------
# GÃœNDEM HABERLERÄ° Ã‡EKME FONKSÄ°YONLARI
# ----------------------------------------------------

RESMI_RSS_URL = "https://www.bbc.com/turkce/index.xml"
Haber_Sayisi = 6
HABERLER_JSON_PATH = pathlib.Path(__file__).parent / "static" / "gundem_haberler.json"


def haberleri_cek_ve_kaydet():
    """
    Belirtilen RSS URL'sinden haberleri Ã§eker ve uygulamanÄ±n eriÅŸebileceÄŸi
    'static' klasÃ¶rÃ¼ne bir JSON dosyasÄ± olarak kaydeder.
    """

    HABERLER_JSON_PATH.parent.mkdir(parents=True, exist_ok=True)

    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Haberler Ã§ekiliyor: {RESMI_RSS_URL}")

    try:
        feed = feedparser.parse(RESMI_RSS_URL)

        haberler = []
        for i, entry in enumerate(feed.entries):
            if i >= Haber_Sayisi:
                break

            haber = {
                "baslik": entry.title,
                "link": entry.link,
                "yayim_tarihi": entry.published if hasattr(entry, 'published')
                else datetime.now().strftime('%d %m %Y %H:%M'),
                "kaynak": "TRT Haber Sondakika"
            }
            haberler.append(haber)

        with open(HABERLER_JSON_PATH, 'w', encoding='utf-8') as f:
            json.dump(haberler, f, ensure_ascii=False, indent=4)

        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {len(haberler)} haber baÅŸarÄ±yla '{HABERLER_JSON_PATH}' dosyasÄ±na kaydedildi.")

    except Exception as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Haber Ã§ekme/kaydetme hatasÄ±: {e}")


def check_with_afad(magnitude, location):
    depremler = get_all_afad_earthquakes()

    if not depremler:
        return None

    if not location and magnitude:
        return None

    for d in depremler:
        yer_temiz = d["Åehir"].strip().lower()

        if magnitude and abs(d["BÃ¼yÃ¼klÃ¼k"] - magnitude) <= 0.3:
            if location and location.lower() in yer_temiz:
                return f"""
### âœ… KESÄ°N DEPREM KONTROLÃœ (AFAD VERÄ°SÄ°)

#### ğŸ¯ Ana Ä°ddia
{location} civarÄ±nda {magnitude} bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde deprem iddiasÄ±.

#### âœ… GÃ¼venilirlik HÃ¼kmÃ¼
**DOÄRULANDI**

#### ğŸ“ KÄ±sa AÃ§Ä±klama
AFAD kayÄ±tlarÄ±nda **{d['Åehir']}** bÃ¶lgesinde **{d['BÃ¼yÃ¼klÃ¼k']}** bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde bir deprem kaydÄ± **BULUNMUÅTUR**.
                """

    return None


# ------- SUNUCU AYAÄA KALKARKEN EN AZ BÄ°R KEZ HABERLERÄ° Ã‡EK --------
try:
    haberleri_cek_ve_kaydet()
except Exception as e:
    print("Ä°lk haber Ã§ekme hatasÄ±:", e)


# ----------------------------------------------------
# 2. FLASK UYGULAMASI VE API
# ----------------------------------------------------

# --- KonfigÃ¼rasyon ---
app = Flask(__name__)
CORS(app)

# Proje kÃ¶k dizini (index.html ve search_page.html burada)
BASE_DIR = pathlib.Path(__file__).parent

# --- HATA AYIKLAMA KONTROLLERÄ° ---
env_path = pathlib.Path('.env')
print(f"DEBUG: .env dosyasÄ±nÄ±n varlÄ±ÄŸÄ±: {env_path.exists()}")

API_KEY = os.getenv("GEMINI_API_KEY")
print(f"DEBUG: API_KEY deÄŸeri okundu: {'VAR' if API_KEY else 'YOK'}")
# --- HATA AYIKLAMA KONTROLLERÄ° SONU ---

if not API_KEY:
    raise ValueError("GEMINI_API_KEY Ã§evre deÄŸiÅŸkeni ayarlanmadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")

client = genai.Client(api_key=API_KEY)
model = 'gemini-2.5-flash'

# GÃœVENÄ°LÄ°R KAYNAKLAR LÄ°STESÄ°
GÃœVENÄ°LÄ°R_SÄ°TELER = [
    "aa.com.tr (Anadolu AjansÄ±)",
    "resmigazete.gov.tr (Resmi Gazete)",
    "valilik siteleri",
    "meb.gov.tr (Milli EÄŸitim BakanlÄ±ÄŸÄ±)",
    "icisleri.gov.tr (Ä°Ã§iÅŸleri BakanlÄ±ÄŸÄ±)",
    "afad.gov.tr",
    "koeri.boun.edu.tr (Kandilli Rasathanesi)"
]

# ---------- Ã–N YÃœZ ROUTE'LARI ----------

@app.route('/')
def index():
    return send_from_directory(str(BASE_DIR), 'index.html')


@app.route('/search')
def search_page():
    return send_from_directory(str(BASE_DIR), 'search_page.html')


# ---------- STATÄ°K DOSYA ROUTE'LARI (CSS / IMG / STATIC) ----------

@app.route('/css/<path:filename>')
def css_files(filename):
    return send_from_directory('css', filename)


@app.route('/img/<path:filename>')
def img_files(filename):
    # static/img klasÃ¶rÃ¼ndeki dosyalarÄ± /img/... ile servis et
    return send_from_directory('static/img', filename)


@app.route('/static/<path:filename>')
def static_files(filename):
    return send_from_directory('static', filename)


# ---------- API ROUTE'LARI ----------

@app.route('/api/dogrula', methods=['POST'])
def dogrulama_islemi():
    simdiki_tarih_metni = "27 Ekim 2025"

    data = request.json
    haber_linki = data.get('link')

    if not haber_linki:
        return jsonify({"hata": "LÃ¼tfen bir haber linki girin."}), 400

    title, haber_metni = get_article_content(haber_linki)

    if title.startswith("Hata:"):
        return jsonify({"hata": title}), 500

    mag, loc = extract_info_from_text(haber_metni)

    afad_sonuc = None
    if mag or loc:
        afad_sonuc = check_with_afad(mag, loc)

        if afad_sonuc:
            return jsonify({
                "basari": True,
                "ozet_ve_dogrulama": afad_sonuc,
                "orijinal_link": haber_linki,
                "kaynak": "AFAD"
            })

    if not haber_metni:
        return jsonify({"hata": "Haber iÃ§eriÄŸi Ã§ekilemedi veya site izin vermiyor."}), 500

    anahtar_kelimeler = ", ".join(
        re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+){0,2}', haber_metni)[:5]
    )
    if not anahtar_kelimeler:
        anahtar_kelimeler = title.split()[:5]

    guvenilir_str = ", ".join(GÃœVENÄ°LÄ°R_SÄ°TELER)

    prompt = f"""
    aÅŸaÄŸÄ±daki haber metnini ve iddialarÄ±nÄ± analiz et.

    **Ã‡OK Ã–NEMLÄ° ZAMAN BÄ°LGÄ°SÄ°:** Åu anki teyit tarihi: {simdiki_tarih_metni}. (Bu bilgiyi Ã§Ä±ktÄ±ya ASLA yazma.)

    **YASAK ve ZORUNLULUKLAR:**
    * **TARÄ°H YASAÄI:** Ã‡Ä±ktÄ±nÄ±n hiÃ§bir yerinde "ÅŸu anki teyit tarihi" veya "{simdiki_tarih_metni}" ifadesini kullanma.
    * **YASAK:** Haberin tarihi gÃ¼ncel teyit tarihiyle aynÄ± veya Ã¶ncesinde olsa bile "henÃ¼z teyit edilemez" hÃ¼kmÃ¼ verme. YALNIZCA olayÄ±n gerÃ§ekleÅŸip gerÃ§ekleÅŸmediÄŸini teyit et.
    * **Ã–NCELÄ°K:** Haberin iÃ§eriÄŸine gÃ¶re (Trafik kazasÄ± ise Ä°Ã§iÅŸleri/Valilik, EÄŸitim ise MEB, Genel ise AA) en uygun gÃ¼venilir kaynaÄŸÄ± ara.

    **HÃ¼kÃ¼m Ä°Ã§in AdÄ±mlar:**
    1. Haberdeki ana iddiayÄ± ve gerÃ§ekleÅŸtiÄŸi iddia edilen tarihi 1-2 cÃ¼mleyle Ã§Ä±kar.
    2. YukarÄ±daki YÃ–NERGEYE uyarak teyitini ara. Ã–zellikle ÅŸu kaynaklarÄ± kullan: {guvenilir_str}.
    3. TÃ¼m analizini, net bir **GÃœVENÄ°LÄ°LÄ°K HÃœKMÃœ** ile sonlandÄ±r.

    **Ã‡Ä±ktÄ± FormatÄ±:**
    Ã‡Ä±ktÄ±n SADECE aÅŸaÄŸÄ±daki gibi kopyalanabilir ve kÄ±sa olmalÄ±dÄ±r. Markdown formatÄ±nÄ± koru.

    ### ğŸš¨ HIZLI DOÄRULUK KONTROLÃœ (GEMINI)

    #### ğŸ¯ Ana Ä°ddia
    [Habere ait 1 cÃ¼mlelik Ã¶zet ve tarihi.]

    #### âœ… GÃ¼venilirlik HÃ¼kmÃ¼
    **[BURAYA SADECE ÅUNLARDAN BÄ°RÄ°NÄ° YAZ: DOÄRULANDI / YANLIÅ / HENÃœZ DOÄRULANAMADI]**

    #### ğŸ“ KÄ±sa AÃ§Ä±klama
    [HÃ¼kmÃ¼nÃ¼ (neden doÄŸru veya yanlÄ±ÅŸ olduÄŸunu) destekleyen 2-3 cÃ¼mlelik Ã§ok kÄ±sa bir aÃ§Ä±klama. AÃ§Ä±klamada teyit tarihi bilgisini KULLANMA. Sadece teyit edildiÄŸi kaynaÄŸÄ± (DHA, Valilik vb.) belirt.]

    Haber Metni:
    ---
    {haber_metni}
    ---
    """

    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config={"temperature": 0.0}
        )

        return jsonify({
            "basari": True,
            "ozet_ve_dogrulama": response.text,
            "orijinal_link": haber_linki,
            "kaynak": "GEMINI"
        })

    except Exception as e:
        return jsonify({"hata": f"Gemini API hatasÄ±: {e}"}), 500


# ----------------------------------------------------
# GÃœNDEM HABERLERÄ° API UÃ‡ NOKTASI
# ----------------------------------------------------

@app.route('/api/gundem', methods=['GET'])
def gundem_haberleri():
    """
    Ã–nceden Ã§ekilmiÅŸ ve JSON dosyasÄ±na kaydedilmiÅŸ haberleri dÃ¶ndÃ¼rÃ¼r.
    """
    try:
        with open(HABERLER_JSON_PATH, 'r', encoding='utf-8') as f:
            haberler = json.load(f)
        return jsonify(haberler)
    except FileNotFoundError:
        return jsonify({"hata": "Haber verisi bulunamadÄ±. LÃ¼tfen app.py'nin haber Ã§ekme fonksiyonunun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun."}), 404
    except Exception as e:
        return jsonify({"hata": f"Haber verisi okunurken hata: {e}"}), 500


# ----------------------------------------------------
# ZAMANLAYICI
# ----------------------------------------------------

def start_scheduler():
    scheduler = BackgroundScheduler()
    scheduler.add_job(haberleri_cek_ve_kaydet, 'interval', minutes=30)
    scheduler.start()
    print("DEBUG: Arka plan haber Ã§ekme zamanlayÄ±cÄ±sÄ± baÅŸlatÄ±ldÄ± (30 dakikada bir).")


if __name__ == '__main__':
    # Lokal Ã§alÄ±ÅŸtÄ±rÄ±rken
    haberleri_cek_ve_kaydet()
    start_scheduler()
    app.run(debug=True, port=5000, use_reloader=False)
