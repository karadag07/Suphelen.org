import os
import requests
import pathlib
from bs4 import BeautifulSoup
from flask import Flask, request, jsonify
from google import genai
from flask_cors import CORS
import re
from datetime import datetime, timedelta 
import feedparser # RSS yayÄ±nlarÄ±nÄ± iÅŸlemek iÃ§in
import json # JSON dosyasÄ± oluÅŸturmak iÃ§in
from apscheduler.schedulers.background import BackgroundScheduler # Arka plan zamanlayÄ±cÄ±sÄ± iÃ§in

# Ã‡evre deÄŸiÅŸkenlerini yÃ¼kleme
from dotenv import load_dotenv
load_dotenv()

# ----------------------------------------------------
# DEPREM VE Ä°Ã‡ERÄ°K FONKSÄ°YONLARI (AynÄ± KalÄ±yor)
# ----------------------------------------------------

def get_article_content(url):
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")
    except Exception as e:
        return "Hata: Siteye eriÅŸilemedi", ""

    title = soup.title.string.strip() if soup.title else "BaÅŸlÄ±k bulunamadÄ±"
    
    texts = []
    for tag in soup.find_all(['p', 'div', 'span', 'article']):
        t = tag.get_text(separator=' ', strip=True)
        if t:
            texts.append(t)
    article_text = " ".join(texts)

    if len(article_text) < 50 and soup.body:
        article_text = soup.body.get_text(separator=' ', strip=True)

    return title, article_text

def extract_info_from_text(text):
    magnitude = None
    location = None

    mag_match = re.search(r'(\d[\.,]?\d?)\s*(?:bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde|ÅŸiddetinde|depremi|sarsÄ±ntÄ±)', text)
    if mag_match:
        magnitude = float(mag_match.group(1).replace(",", "."))

    location_match = re.search(r'([A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+)\s*(?:\'de|\'da|\'ta|\'te|yakÄ±nlarÄ±nda)?\s+(?:deprem|sarsÄ±ntÄ±)', text)
    if location_match:
        location = location_match.group(1)

    return magnitude, location

def get_all_afad_earthquakes():
    AFAD_URL = "https://deprem.afad.gov.tr/last-earthquakes.html"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(AFAD_URL, headers=headers, timeout=10)
        res.raise_for_status()
        res.encoding = "utf-8"
        soup = BeautifulSoup(res.text, "html.parser")
        table = soup.find("table")
    except:
        return []

    if not table:
        return []

    rows = table.find_all("tr")[1:]
    records = []

    for row in rows:
        cols = row.find_all("td")
        if len(cols) >= 7:
            try:
                buyukluk = float(cols[5].text.strip())
            except:
                buyukluk = 0.0
            
            sehir = cols[6].text.strip()
            
            records.append({
                "BÃ¼yÃ¼klÃ¼k": buyukluk,
                "Åehir": sehir
            })
    return records

# ----------------------------------------------------
# GÃœNDEM HABERLERÄ° Ã‡EKME FONKSÄ°YONLARI
# ----------------------------------------------------

# TRT Haber Sondakika RSS'i gibi doÄŸrulanmÄ±ÅŸ bir kaynaktan veri Ã§eker
RESMI_RSS_URL = "https://www.bbc.com/turkce/index.xml"
Haber_Sayisi = 6
HABERLER_JSON_PATH = pathlib.Path(__file__).parent / "static" / "gundem_haberler.json"

def haberleri_cek_ve_kaydet():
    """
    Belirtilen RSS URL'sinden haberleri Ã§eker ve uygulamanÄ±n eriÅŸebileceÄŸi
    'static' klasÃ¶rÃ¼ne bir JSON dosyasÄ± olarak kaydeder.
    """
    
    # Static klasÃ¶rÃ¼nÃ¼n varlÄ±ÄŸÄ±nÄ± kontrol et
    HABERLER_JSON_PATH.parent.mkdir(parents=True, exist_ok=True)

    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Haberler Ã§ekiliyor: {RESMI_RSS_URL}")
    
    try:
        # RSS yayÄ±nÄ±nÄ± Ã§ek
        feed = feedparser.parse(RESMI_RSS_URL)
        
        # Sadece belirlenen sayÄ±da haberi al
        haberler = []
        for i, entry in enumerate(feed.entries):
            if i >= Haber_Sayisi:
                break
                
            # Gelen veriyi temizle ve yapÄ±landÄ±r
            haber = {
                "baslik": entry.title,
                "link": entry.link,
                "yayim_tarihi": entry.published if hasattr(entry, 'published') else datetime.now().strftime('%d %m %Y %H:%M'),
                "kaynak": "TRT Haber Sondakika"
            }
            haberler.append(haber)

        # Veriyi bir JSON dosyasÄ±na kaydet
        with open(HABERLER_JSON_PATH, 'w', encoding='utf-8') as f:
            # JSON formatÄ±nda kaydederken TÃ¼rkÃ§e karakter sorunu olmamasÄ± iÃ§in ensure_ascii=False
            json.dump(haberler, f, ensure_ascii=False, indent=4)
        
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {len(haberler)} haber baÅŸarÄ±yla '{HABERLER_JSON_PATH}' dosyasÄ±na kaydedildi.")
        
    except Exception as e:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Haber Ã§ekme/kaydetme hatasÄ±: {e}")
        # Hata durumunda boÅŸ bir dosya oluÅŸturmak veya bir hata mesajÄ± loglamak faydalÄ± olabilir.


def check_with_afad(magnitude, location):
    depremler = get_all_afad_earthquakes()

    if not depremler:
        return None 

    if not location and magnitude:
        return None 

    for d in depremler:
        yer_temiz = d["Åehir"].strip().lower()
        
        if magnitude and abs(d["BÃ¼yÃ¼klÃ¼k"] - magnitude) <= 0.3: 
            if location and location.lower() in yer_temiz: 
                return f"""
### âœ… KESÄ°N DEPREM KONTROLÃœ (AFAD VERÄ°SÄ°)

#### ğŸ¯ Ana Ä°ddia
{location} civarÄ±nda {magnitude} bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde deprem iddiasÄ±.

#### âœ… GÃ¼venilirlik HÃ¼kmÃ¼
**DOÄRULANDI**

#### ğŸ“ KÄ±sa AÃ§Ä±klama
AFAD kayÄ±tlarÄ±nda **{d['Åehir']}** bÃ¶lgesinde **{d['BÃ¼yÃ¼klÃ¼k']}** bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde bir deprem kaydÄ± **BULUNMUÅTUR**.
                """
    
    return None 


# ----------------------------------------------------
# 2. FLASK UYGULAMASI VE API
# ----------------------------------------------------
from flask import send_from_directory

# --- KonfigÃ¼rasyon ---
app = Flask(__name__)
CORS(app)

# Proje kÃ¶k dizini (index.html ve search_page.html burada)
BASE_DIR = pathlib.Path(__file__).parent


# --- HATA AYIKLAMA KONTROLLERÄ° ---
env_path = pathlib.Path('.env')
print(f"DEBUG: .env dosyasÄ±nÄ±n varlÄ±ÄŸÄ±: {env_path.exists()}") 

API_KEY = os.getenv("GEMINI_API_KEY")
print(f"DEBUG: API_KEY deÄŸeri okundu: {'VAR' if API_KEY else 'YOK'}") 
# --- HATA AYIKLAMA KONTROLLERÄ° SONU ---

if not API_KEY:
    raise ValueError("GEMINI_API_KEY Ã§evre deÄŸiÅŸkeni ayarlanmadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")

client = genai.Client(api_key=API_KEY)
model = 'gemini-2.5-flash'

# GÃœVENÄ°LÄ°R KAYNAKLAR LÄ°STESÄ° (KullanÄ±cÄ± Ä°steÄŸine GÃ¶re GÃ¼ncellendi)
GÃœVENÄ°LÄ°R_SÄ°TELER = [
    "aa.com.tr (Anadolu AjansÄ±)", 
    "resmigazete.gov.tr (Resmi Gazete)",
    "valilik siteleri", 
    "meb.gov.tr (Milli EÄŸitim BakanlÄ±ÄŸÄ±)", 
    "icisleri.gov.tr (Ä°Ã§iÅŸleri BakanlÄ±ÄŸÄ±)",
    "afad.gov.tr", 
    "koeri.boun.edu.tr (Kandilli Rasathanesi)"
]

# ---------- Ã–N YÃœZ ROUTE'LARI ----------

@app.route('/')
def index():
    # Proje kÃ¶k dizinindeki index.html dosyasÄ±nÄ± dÃ¶ner
    return send_from_directory(str(BASE_DIR), 'index.html')

@app.route('/search')
def search_page():
    # Proje kÃ¶k dizinindeki search_page.html dosyasÄ±nÄ± dÃ¶ner
    return send_from_directory(str(BASE_DIR), 'search_page.html')

# ---------- API ROUTE'LARI ----------

@app.route('/api/dogrula', methods=['POST'])
def dogrulama_islemi():
    # GÃœNCEL TARÄ°HÄ°NÄ°ZÄ° BURADA SÄ°ZÄ°N Ä°STEDÄ°ÄÄ°NÄ°Z ÅEKÄ°LDE SABÄ°TLÄ°YORUZ
    simdiki_tarih_metni = "27 Ekim 2025" 
    
    data = request.json
    haber_linki = data.get('link')

    if not haber_linki:
        return jsonify({"hata": "LÃ¼tfen bir haber linki girin."}), 400

    title, haber_metni = get_article_content(haber_linki)

    if title.startswith("Hata:"):
        return jsonify({"hata": title}), 500

    # 2. DEPREM KONTROLÃœ YAP (Ã–ncelikli Ä°ÅŸlem)
    mag, loc = extract_info_from_text(haber_metni)
    
    afad_sonuc = None
    if mag or loc:
        afad_sonuc = check_with_afad(mag, loc)
        
        if afad_sonuc:
            return jsonify({
                "basari": True,
                "ozet_ve_dogrulama": afad_sonuc,
                "orijinal_link": haber_linki,
                "kaynak": "AFAD"
            })

    # 3. AFAD/DEPREM DeÄŸilse, GEMINI'YÄ° Ã‡ALIÅTIR
    
    if not haber_metni:
        return jsonify({"hata": "Haber iÃ§eriÄŸi Ã§ekilemedi veya site izin vermiyor."}), 500

    
    # Haber metninden anahtar kelimeleri Ã§Ä±kar
    anahtar_kelimeler = ", ".join(re.findall(r'[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+(?:\s[A-ZÃ‡ÄÄ°Ã–ÅÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]+){0,2}', haber_metni)[:5])
    if not anahtar_kelimeler:
        anahtar_kelimeler = title.split()[:5]
        
    guvenilir_str = ", ".join(GÃœVENÄ°LÄ°R_SÄ°TELER)
    
    # PROMPT: Genel Habere YÃ¶nlendirme ve Tarih Sabitleme TalimatÄ±
    prompt = f"""
    ÅŸaÄŸÄ±daki haber metnini ve iddialarÄ±nÄ± analiz et.

    **Ã‡OK Ã–NEMLÄ° ZAMAN BÄ°LGÄ°SÄ°:** Åu anki teyit tarihi: {simdiki_tarih_metni}. (Bu bilgiyi Ã§Ä±ktÄ±ya ASLA yazma.)

    **YASAK ve ZORUNLULUKLAR:**
    * **TARÄ°H YASAÄI:** Ã‡Ä±ktÄ±nÄ±n hiÃ§bir yerinde "ÅŸu anki teyit tarihi" veya "{simdiki_tarih_metni}" ifadesini kullanma.
    * **YASAK:** Haberin tarihi gÃ¼ncel teyit tarihiyle aynÄ± veya Ã¶ncesinde olsa bile "henÃ¼z teyit edilemez" hÃ¼kmÃ¼ verme. YALNIZCA olayÄ±n gerÃ§ekleÅŸip gerÃ§ekleÅŸmediÄŸini teyit et.
    * **Ã–NCELÄ°K:** Haberin iÃ§eriÄŸine gÃ¶re (Trafik kazasÄ± ise Ä°Ã§iÅŸleri/Valilik, EÄŸitim ise MEB, Genel ise AA) en uygun gÃ¼venilir kaynaÄŸÄ± ara.

    **HÃ¼kÃ¼m Ä°Ã§in AdÄ±mlar:**
    1. Haberdeki ana iddiayÄ± ve gerÃ§ekleÅŸtiÄŸi iddia edilen tarihi 1-2 cÃ¼mleyle Ã§Ä±kar.
    2. YukarÄ±daki YÃ–NERGEYE uyarak teyitini ara. Ã–zellikle ÅŸu kaynaklarÄ± kullan: {guvenilir_str}.
    3. TÃ¼m analizini, net bir **GÃœVENÄ°LÄ°LÄ°K HÃœKMÃœ** ile sonlandÄ±r.

    **Ã‡Ä±ktÄ± FormatÄ±:**
    Ã‡Ä±ktÄ±n SADECE aÅŸaÄŸÄ±daki gibi kopyalanabilir ve kÄ±sa olmalÄ±dÄ±r. Markdown formatÄ±nÄ± koru.

    ### ğŸš¨ HIZLI DOÄRULUK KONTROLÃœ (GEMINI)

    #### ğŸ¯ Ana Ä°ddia
    [Habere ait 1 cÃ¼mlelik Ã¶zet ve tarihi.]

    #### âœ… GÃ¼venilirlik HÃ¼kmÃ¼
    **[BURAYA SADECE ÅUNLARDAN BÄ°RÄ°NÄ° YAZ: DOÄRULANDI / YANLIÅ / HENÃœZ DOÄRULANAMADI]**

    #### ğŸ“ KÄ±sa AÃ§Ä±klama
    [HÃ¼kmÃ¼nÃ¼ (neden doÄŸru veya yanlÄ±ÅŸ olduÄŸunu) destekleyen 2-3 cÃ¼mlelik Ã§ok kÄ±sa bir aÃ§Ä±klama. AÃ§Ä±klamada teyit tarihi bilgisini KULLANMA. Sadece teyit edildiÄŸi kaynaÄŸÄ± (DHA, Valilik vb.) belirt.]

    Haber Metni:
    ---
    {haber_metni}
    ---
    """

    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config={"temperature": 0.0} 
        )
        
        return jsonify({
            "basari": True,
            "ozet_ve_dogrulama": response.text,
            "orijinal_link": haber_linki,
            "kaynak": "GEMINI"
        })

    except Exception as e:
        return jsonify({"hata": f"Gemini API hatasÄ±: {e}"}), 500

# ----------------------------------------------------
# GÃœNDEM HABERLERÄ° API UÃ‡ NOKTASI
# ----------------------------------------------------

@app.route('/api/gundem', methods=['GET'])
def gundem_haberleri():
    """
    Ã–nceden Ã§ekilmiÅŸ ve JSON dosyasÄ±na kaydedilmiÅŸ haberleri dÃ¶ndÃ¼rÃ¼r.
    """
    try:
        # Flask, statik dosyalara eriÅŸim iÃ§in doÄŸru yolu kullanÄ±r
        with open(HABERLER_JSON_PATH, 'r', encoding='utf-8') as f:
            haberler = json.load(f)
        return jsonify(haberler)
    except FileNotFoundError:
        return jsonify({"hata": "Haber verisi bulunamadÄ±. LÃ¼tfen app.py'nin haber Ã§ekme fonksiyonunun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun."}), 404
    except Exception as e:
        return jsonify({"hata": f"Haber verisi okunurken hata: {e}"}), 500

# ----------------------------------------------------
# GÃœNDEM HABERLERÄ° API UÃ‡ NOKTASI SONU
# ----------------------------------------------------

# Otomatik haber Ã§ekme iÅŸini baÅŸlatan fonksiyon
def start_scheduler():
    # GÃ¼ncelleme iÅŸi: Haberleri her 30 dakikada bir Ã§ek
    scheduler = BackgroundScheduler()
    scheduler.add_job(haberleri_cek_ve_kaydet, 'interval', minutes=30)
    scheduler.start()
    print("DEBUG: Arka plan haber Ã§ekme zamanlayÄ±cÄ±sÄ± baÅŸlatÄ±ldÄ± (30 dakikada bir).")

if __name__ == '__main__':
    # Flask uygulamasÄ±nÄ±n baÅŸlatÄ±lmasÄ±ndan hemen Ã¶nce ilk Ã§ekimi yap
    haberleri_cek_ve_kaydet()
    # ZamanlayÄ±cÄ±yÄ± baÅŸlat
    start_scheduler() 
    # use_reloader=False ayarÄ±, debug=True iken Flask'in iki kez baÅŸlamasÄ±nÄ± engeller.
    app.run(debug=True, port=5000, use_reloader=False)
